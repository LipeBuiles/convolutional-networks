{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elpinchepastel/convolutional-networks/blob/master/Taller.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTD5u8PXMCTT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim  \n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms  \n",
        "import torchvision\n",
        "import os\n",
        "from time import time \n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from torch.utils.data import (Dataset, DataLoader)  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49AvvvWJMgsq",
        "outputId": "e305976e-408e-4399-d0a6-91bcafa7b64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbg6_VVjMpvF",
        "outputId": "7d46dbe8-3ea8-4737-ceff-7da520e02b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)\n",
        "classes = ('Circulo', 'Cuadrado', 'Estrella', 'Triangulo')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFLxopRGNN_l"
      },
      "source": [
        "## Esto es lo que vimos en clase\n",
        "class ShapesDataset (Dataset):\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "    image = io.imread(img_path)\n",
        "\n",
        "    image = resize(image, (32,32))\n",
        "    \n",
        "    y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    \n",
        "    return (image, y_label)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtdSRS6IUefR"
      },
      "source": [
        "## Ac√° instanciamos o creamos el objeto \"dataset\" de la clase \"ShapesDataset\"\n",
        "## Le pasamos los directorios de los archivos, cambian \"CSVS\" y \"CNNS\" segun la carpeta en la que tienen los datos\n",
        "dataset = ShapesDataset(\n",
        "    csv_file=\"/content/drive/My Drive/IA/Archivos_Shapes/Muestra2K.csv\",\n",
        "    root_dir=\"/content/drive/My Drive/IA/Archivos_Shapes/muestra\",\n",
        "    transform=transforms.ToTensor())## Transformamos los datos a tensor"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOfYxQ76UgvX",
        "outputId": "fc3cd0e6-33d2-45f0-aaa2-a029ca260225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "## Este codigo es solamente para que puedan ver las 4 formas, no es esencial\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    imagen, label = dataset[(i+1)*510]\n",
        "    ax = plt.subplot(2, 2, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample {}, Label: {}'.format(i+1,classes[label] ))\n",
        "    ax.axis('off')\n",
        "    plt.imshow(imagen.squeeze_(0), cmap='gray')\n",
        "\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPw43qeaUit3"
      },
      "source": [
        " batch_size = 1\n",
        "## Definimos el tama√±o del batch_size en 1 (La cantidad de imagenes)\n",
        "## Partimos el dataset en 80% entrenamiento, 20% prueba, juntos suman 2044\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [1636, 408])\n",
        "## Creamos los objetos que nos van a permitir cargar los datos en nuestra red (Objetos iterables de los que les hablaba al final de la sesion 1)\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVRtRMiKUowZ",
        "outputId": "b734c464-2f53-4654-fcdb-b1ef2e4be9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Net (nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        ## LLenar con las capas de convoluci√≥n   y pooling\n",
        "        \n",
        "    def forward (self, x):\n",
        "    \n",
        "        \n",
        "        ## Llenar con el orden\n",
        "        \n",
        "        return F.log_softmax(x, dim=1) ## Funcion de activaci√≥n softmax\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "net = Net()\n",
        "net = net.double()\n",
        "#Uncoment for training with cuda\n",
        "net.to(device)\n",
        "print(net)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTYf7WLIU29L"
      },
      "source": [
        "- Capa de entrada **## Recuerden que la capa de entrada no se debe codificar.**\n",
        "- Capa convolucional1: in_Channels = 1, Out_Channels = 32, Kernel_size = 3 \n",
        "- Function de activaci√≥n Relu  \n",
        "- Capa convolucional2: in_Channels = 32, Out_Channels = 32, Kernel_size = 3 \n",
        "- Capa de Max Pooling1: Kernel_size = 2\n",
        "- Function de activaci√≥n Relu  \n",
        "- Capa convolucional3: in_Channels = 32, Out_Channels = 64, Kernel_size = 3 \n",
        "- Capa de Max Pooling2: Kernel_size = 2\n",
        "- Funci√≥n de activaci√≥n Relu  \n",
        "- Flatten\n",
        "- Capa lineal 1: n_Channels = ?, Out_Channels = 256\n",
        "- Funci√≥n de activaci√≥n Relu  \n",
        "- Capa lineal 2: n_Channels = 256, Out_Channels = 4\n",
        "- Funci√≥n de activaci√≥n: F.log_softmax(x, dim = 1)\n",
        "\n",
        "**Por fuera de la clase:**\n",
        "\n",
        "net = Net() \n",
        "\n",
        "net = net.double() ## Se convierten los par√°metros de la red al mismo tipo de tensor que los datos de entrada\n",
        "\n",
        "net.to(device) ## Se lleva la red a GPU\n",
        "\n",
        "Tener en cuenta que el \"Net\" es el nombre que le dieron a la clase (red), \"net\" es solo un nombre que yo escogi para darle a un nuevo objeto de la clase \"Net\".\n",
        "\n",
        "\n",
        "## NOTA 1: Si cambian el nombre de la clase \"Net\" al momento de definirla deben cambiar Net() por ***(), donde los asteriscos son el nombre que le dieron a su clase, por ejemplo: \n",
        "\n",
        "net = Neuronas() \n",
        "\n",
        "## NOTA 2: Si cambian el nombre del objeto \"net\" deben cambiarlo en donde aparezca, por ejemplo: \n",
        "\n",
        "red = Net()\n",
        "\n",
        "red = red.double()\n",
        "\n",
        "red.to(device)\n",
        "\n",
        "## NOTA 3: En la capa lineal 1 hace falta el valor de entrada, debe ser calculado con la ecuaci√≥n que dejo m√°s abajo de la siguiente forma:\n",
        "\n",
        "La capa de entrada recibe 32x32 pixeles, la primera capa convolucional recibe esos pixeles y aplica un kernel de 3x3, no aplica padding y como no aparece stride por default es 1.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "[(32-3+2*0)/1]+1 = 30\n",
        "\n",
        "30 es la cantidad de pixeles, recuerden que en las capas convolucionales no es necesario indicar los pixeles sino la cantidad de canales, deben seguir aplicando la ecuaci√≥n para cada capa convolucional (incluidas las capas de pooling), al llegar a la ultima capa convolucional calculan la cantidad de pixeles y eso lo elevan al cuadrado (multiplican por si mismo el resultado, alto por ancho), luego multiplican por la cantidad de canales de salida que seria 64 y obtendr√°n el par√°metro que falta.\n",
        "\n",
        "**Recuerden que las capas de pooling de 2x2 reducen a la mitad el tama√±o de la imagen, y que si no es un numero entero queda del tama√±o sin la parte decimal.**\n",
        "\n",
        "## Ecuaci√≥n capas convolucionales: [(W‚àíK+2P)/S]+1\n",
        "\n",
        "Donde: \n",
        "\n",
        "\"W\" es el ancho de la imagen, la ecuacion se hace para alto y ancho, pero como es el mismo solo la hacemos una vez, por eso al final debemos elevar al cuadrado o multiplicar por si mismo el valor de los pixeles, para obtener W*H, H es el alto.\n",
        "\n",
        "\"K\" es el kernel size de esa capa, como todos son 3 siempre es el mismo.\n",
        "\n",
        "\"P\" es el padding, como no hay es 2*0.\n",
        "\n",
        "\"S\" es el stride, como no se especifica por default es 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LCSE6YjU4M_"
      },
      "source": [
        "import torch.optim as optim\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGArZKr2W9hq"
      },
      "source": [
        "num_epochs = 2\n",
        "time0 = time()\n",
        "for epoch in range(num_epochs):  \n",
        "    print(\"Epoch: \", epoch)\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(???, 0):\n",
        "        \n",
        "        ## dividir entradas y etiquetas y llevarlas a GPU\n",
        "        \n",
        "        ## Gradientes a cero\n",
        "\n",
        "        ## forward + backward + optimize\n",
        "\n",
        "        ## Acumular perdida\n",
        "        \n",
        "\n",
        "    else:\n",
        "        print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss /len(train_loader)))\n",
        "            \n",
        "\n",
        "print('Entrenamiento finalizado')\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYjxuzu-YBAu"
      },
      "source": [
        "path = 'mired.pth'\n",
        "torch.save(net.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tieLv1ogY_Kz"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "class_correct = [0,0,0,0]\n",
        "class_total = [0,0,0,0]\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if (predicted == labels):\n",
        "            class_correct[labels] += 1\n",
        "        else:\n",
        "            class_total[labels] += 1\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-sh-91yZDoj"
      },
      "source": [
        "print(class_correct)\n",
        "print(class_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfnNnIoYZieW"
      },
      "source": [
        "## Parte 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRZ07djEZldD"
      },
      "source": [
        "## Desarrollo\n",
        "- Identificar el objeto iterable que hace falta en el loop de entrenamiento. (Esta identificado con \"???\")\n",
        "\n",
        "Nota 1: recuerden que el objeto sobre el que se itera una vez se ingresa al loop de las epocas es el objeto construido con los datos de entrenamiento y sus respectivas etiquetas.\n",
        "\n",
        "- Llevar los gradientes a cero para garantizar el correcto calculo de los gradientes en cada iteracion.\n",
        "\n",
        "- Aplicar el forward, backward, optimize\n",
        "\n",
        "Nota 2: Recuerden que para calcular el backward deben propagar la perdida, por tanto deben calcular la perdida antes.\n",
        "\n",
        "- Acumular la perdida de cada iteracion y dividirla sobre el tama√±o del objeto iterable que falta para saber la perdida sobre ese batch.(La parte de la divisi√≥n ya esta en el print)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fl9-Seej4b"
      },
      "source": [
        "## Fecha limite de entrega: Martes 6 de Octubre"
      ]
    }
  ]
}